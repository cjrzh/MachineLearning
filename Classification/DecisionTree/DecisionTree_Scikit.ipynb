{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读数据\n",
    "#需要将离散输入转换成向量表示\n",
    "featureList = []\n",
    "labelList = []\n",
    "with open('AllElectronics.csv', newline='') as allElectronicsData:\n",
    "    reader = csv.reader(allElectronicsData)\n",
    "    headers=reader.__next__()\n",
    "    for row in reader:\n",
    "        labelList.append(row[-1])\n",
    "        rowDict={}\n",
    "        for i in range(1,len(row)-1):\n",
    "            rowDict[headers[i]]=row[i]\n",
    "        featureList.append(rowDict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 'youth', 'credit_rating': 'fair', 'income': 'high', 'student': 'no'},\n",
       " {'age': 'youth',\n",
       "  'credit_rating': 'excellent',\n",
       "  'income': 'high',\n",
       "  'student': 'no'},\n",
       " {'age': 'middle_aged',\n",
       "  'credit_rating': 'fair',\n",
       "  'income': 'high',\n",
       "  'student': 'no'},\n",
       " {'age': 'senior',\n",
       "  'credit_rating': 'fair',\n",
       "  'income': 'medium',\n",
       "  'student': 'no'},\n",
       " {'age': 'senior', 'credit_rating': 'fair', 'income': 'low', 'student': 'yes'},\n",
       " {'age': 'senior',\n",
       "  'credit_rating': 'excellent',\n",
       "  'income': 'low',\n",
       "  'student': 'yes'},\n",
       " {'age': 'middle_aged',\n",
       "  'credit_rating': 'excellent',\n",
       "  'income': 'low',\n",
       "  'student': 'yes'},\n",
       " {'age': 'youth',\n",
       "  'credit_rating': 'fair',\n",
       "  'income': 'medium',\n",
       "  'student': 'no'},\n",
       " {'age': 'youth', 'credit_rating': 'fair', 'income': 'low', 'student': 'yes'},\n",
       " {'age': 'senior',\n",
       "  'credit_rating': 'fair',\n",
       "  'income': 'medium',\n",
       "  'student': 'yes'},\n",
       " {'age': 'youth',\n",
       "  'credit_rating': 'excellent',\n",
       "  'income': 'medium',\n",
       "  'student': 'yes'},\n",
       " {'age': 'middle_aged',\n",
       "  'credit_rating': 'excellent',\n",
       "  'income': 'medium',\n",
       "  'student': 'no'},\n",
       " {'age': 'middle_aged',\n",
       "  'credit_rating': 'fair',\n",
       "  'income': 'high',\n",
       "  'student': 'yes'},\n",
       " {'age': 'senior',\n",
       "  'credit_rating': 'excellent',\n",
       "  'income': 'medium',\n",
       "  'student': 'no'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DictVectorizer in module sklearn.feature_extraction.dict_vectorizer:\n",
      "\n",
      "class DictVectorizer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Transforms lists of feature-value mappings to vectors.\n",
      " |  \n",
      " |  This transformer turns lists of mappings (dict-like objects) of feature\n",
      " |  names to feature values into Numpy arrays or scipy.sparse matrices for use\n",
      " |  with scikit-learn estimators.\n",
      " |  \n",
      " |  When feature values are strings, this transformer will do a binary one-hot\n",
      " |  (aka one-of-K) coding: one boolean-valued feature is constructed for each\n",
      " |  of the possible string values that the feature can take on. For instance,\n",
      " |  a feature \"f\" that can take on the values \"ham\" and \"spam\" will become two\n",
      " |  features in the output, one signifying \"f=ham\", the other \"f=spam\".\n",
      " |  \n",
      " |  Features that do not occur in a sample (mapping) will have a zero value\n",
      " |  in the resulting array/matrix.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <dict_feature_extraction>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  dtype : callable, optional\n",
      " |      The type of feature values. Passed to Numpy array/scipy.sparse matrix\n",
      " |      constructors as the dtype argument.\n",
      " |  separator: string, optional\n",
      " |      Separator string used when constructing new features for one-hot\n",
      " |      coding.\n",
      " |  sparse: boolean, optional.\n",
      " |      Whether transform should produce scipy.sparse matrices.\n",
      " |      True by default.\n",
      " |  sort: boolean, optional.\n",
      " |      Whether ``feature_names_`` and ``vocabulary_`` should be sorted when fitting.\n",
      " |      True by default.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  vocabulary_ : dict\n",
      " |      A dictionary mapping feature names to feature indices.\n",
      " |  \n",
      " |  feature_names_ : list\n",
      " |      A list of length n_features containing the feature names (e.g., \"f=ham\"\n",
      " |      and \"f=spam\").\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.feature_extraction import DictVectorizer\n",
      " |  >>> v = DictVectorizer(sparse=False)\n",
      " |  >>> D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
      " |  >>> X = v.fit_transform(D)\n",
      " |  >>> X\n",
      " |  array([[ 2.,  0.,  1.],\n",
      " |         [ 0.,  1.,  3.]])\n",
      " |  >>> v.inverse_transform(X) ==         [{'bar': 2.0, 'foo': 1.0}, {'baz': 1.0, 'foo': 3.0}]\n",
      " |  True\n",
      " |  >>> v.transform({'foo': 4, 'unseen_feature': 3})\n",
      " |  array([[ 0.,  0.,  4.]])\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  FeatureHasher : performs vectorization using only a hash function.\n",
      " |  sklearn.preprocessing.OneHotEncoder : handles nominal/categorical features\n",
      " |    encoded as columns of integers.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DictVectorizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dtype=<class 'numpy.float64'>, separator='=', sparse=True, sort=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Learn a list of feature name -> indices mappings.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : Mapping or iterable over Mappings\n",
      " |          Dict(s) or Mapping(s) from feature names (arbitrary Python\n",
      " |          objects) to feature values (strings or convertible to dtype).\n",
      " |      y : (ignored)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Learn a list of feature name -> indices mappings and transform X.\n",
      " |      \n",
      " |      Like fit(X) followed by transform(X), but does not require\n",
      " |      materializing X in memory.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : Mapping or iterable over Mappings\n",
      " |          Dict(s) or Mapping(s) from feature names (arbitrary Python\n",
      " |          objects) to feature values (strings or convertible to dtype).\n",
      " |      y : (ignored)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xa : {array, sparse matrix}\n",
      " |          Feature vectors; always 2-d.\n",
      " |  \n",
      " |  get_feature_names(self)\n",
      " |      Returns a list of feature names, ordered by their indices.\n",
      " |      \n",
      " |      If one-of-K coding is applied to categorical features, this will\n",
      " |      include the constructed feature names but not the original ones.\n",
      " |  \n",
      " |  inverse_transform(self, X, dict_type=<class 'dict'>)\n",
      " |      Transform array or sparse matrix X back to feature mappings.\n",
      " |      \n",
      " |      X must have been produced by this DictVectorizer's transform or\n",
      " |      fit_transform method; it may only have passed through transformers\n",
      " |      that preserve the number of features and their order.\n",
      " |      \n",
      " |      In the case of one-hot/one-of-K coding, the constructed feature\n",
      " |      names and values are returned rather than the original ones.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Sample matrix.\n",
      " |      dict_type : callable, optional\n",
      " |          Constructor for feature mappings. Must conform to the\n",
      " |          collections.Mapping API.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      D : list of dict_type objects, length = n_samples\n",
      " |          Feature mappings for the samples in X.\n",
      " |  \n",
      " |  restrict(self, support, indices=False)\n",
      " |      Restrict the features to those in support using feature selection.\n",
      " |      \n",
      " |      This function modifies the estimator in-place.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      support : array-like\n",
      " |          Boolean mask or list of indices (as returned by the get_support\n",
      " |          member of feature selectors).\n",
      " |      indices : boolean, optional\n",
      " |          Whether support is a list of indices.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from sklearn.feature_extraction import DictVectorizer\n",
      " |      >>> from sklearn.feature_selection import SelectKBest, chi2\n",
      " |      >>> v = DictVectorizer()\n",
      " |      >>> D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
      " |      >>> X = v.fit_transform(D)\n",
      " |      >>> support = SelectKBest(chi2, k=2).fit(X, [0, 1])\n",
      " |      >>> v.get_feature_names()\n",
      " |      ['bar', 'baz', 'foo']\n",
      " |      >>> v.restrict(support.get_support()) # doctest: +ELLIPSIS\n",
      " |      DictVectorizer(dtype=..., separator='=', sort=True,\n",
      " |              sparse=True)\n",
      " |      >>> v.get_feature_names()\n",
      " |      ['bar', 'foo']\n",
      " |  \n",
      " |  transform(self, X, y=None)\n",
      " |      Transform feature->value dicts to array or sparse matrix.\n",
      " |      \n",
      " |      Named features not encountered during fit or fit_transform will be\n",
      " |      silently ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : Mapping or iterable over Mappings, length = n_samples\n",
      " |          Dict(s) or Mapping(s) from feature names (arbitrary Python\n",
      " |          objects) to feature values (strings or convertible to dtype).\n",
      " |      y : (ignored)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xa : {array, sparse matrix}\n",
      " |          Feature vectors; always 2-d.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep: boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DictVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "dummyX=vec.fit_transform(featureList).toarray()\n",
    "dummyX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age=middle_aged',\n",
       " 'age=senior',\n",
       " 'age=youth',\n",
       " 'credit_rating=excellent',\n",
       " 'credit_rating=fair',\n",
       " 'income=high',\n",
       " 'income=low',\n",
       " 'income=medium',\n",
       " 'student=no',\n",
       " 'student=yes']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LabelBinarizer in module sklearn.preprocessing.label object:\n",
      "\n",
      "class LabelBinarizer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Binarize labels in a one-vs-all fashion\n",
      " |  \n",
      " |  Several regression and binary classification algorithms are\n",
      " |  available in the scikit. A simple way to extend these algorithms\n",
      " |  to the multi-class classification case is to use the so-called\n",
      " |  one-vs-all scheme.\n",
      " |  \n",
      " |  At learning time, this simply consists in learning one regressor\n",
      " |  or binary classifier per class. In doing so, one needs to convert\n",
      " |  multi-class labels to binary labels (belong or does not belong\n",
      " |  to the class). LabelBinarizer makes this process easy with the\n",
      " |  transform method.\n",
      " |  \n",
      " |  At prediction time, one assigns the class for which the corresponding\n",
      " |  model gave the greatest confidence. LabelBinarizer makes this easy\n",
      " |  with the inverse_transform method.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  neg_label : int (default: 0)\n",
      " |      Value with which negative labels must be encoded.\n",
      " |  \n",
      " |  pos_label : int (default: 1)\n",
      " |      Value with which positive labels must be encoded.\n",
      " |  \n",
      " |  sparse_output : boolean (default: False)\n",
      " |      True if the returned array from transform is desired to be in sparse\n",
      " |      CSR format.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  classes_ : array of shape [n_class]\n",
      " |      Holds the label for each class.\n",
      " |  \n",
      " |  y_type_ : str,\n",
      " |      Represents the type of the target data as evaluated by\n",
      " |      utils.multiclass.type_of_target. Possible type are 'continuous',\n",
      " |      'continuous-multioutput', 'binary', 'multiclass',\n",
      " |      'mutliclass-multioutput', 'multilabel-indicator', and 'unknown'.\n",
      " |  \n",
      " |  multilabel_ : boolean\n",
      " |      True if the transformer was fitted on a multilabel rather than a\n",
      " |      multiclass set of labels. The ``multilabel_`` attribute is deprecated\n",
      " |      and will be removed in 0.18\n",
      " |  \n",
      " |  sparse_input_ : boolean,\n",
      " |      True if the input data to transform is given as a sparse matrix, False\n",
      " |      otherwise.\n",
      " |  \n",
      " |  indicator_matrix_ : str\n",
      " |      'sparse' when the input data to tansform is a multilable-indicator and\n",
      " |      is sparse, None otherwise. The ``indicator_matrix_`` attribute is\n",
      " |      deprecated as of version 0.16 and will be removed in 0.18\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import preprocessing\n",
      " |  >>> lb = preprocessing.LabelBinarizer()\n",
      " |  >>> lb.fit([1, 2, 6, 4, 2])\n",
      " |  LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
      " |  >>> lb.classes_\n",
      " |  array([1, 2, 4, 6])\n",
      " |  >>> lb.transform([1, 6])\n",
      " |  array([[1, 0, 0, 0],\n",
      " |         [0, 0, 0, 1]])\n",
      " |  \n",
      " |  Binary targets transform to a column vector\n",
      " |  \n",
      " |  >>> lb = preprocessing.LabelBinarizer()\n",
      " |  >>> lb.fit_transform(['yes', 'no', 'no', 'yes'])\n",
      " |  array([[1],\n",
      " |         [0],\n",
      " |         [0],\n",
      " |         [1]])\n",
      " |  \n",
      " |  Passing a 2D matrix for multilabel classification\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> lb.fit(np.array([[0, 1, 1], [1, 0, 0]]))\n",
      " |  LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
      " |  >>> lb.classes_\n",
      " |  array([0, 1, 2])\n",
      " |  >>> lb.transform([0, 1, 2, 1])\n",
      " |  array([[1, 0, 0],\n",
      " |         [0, 1, 0],\n",
      " |         [0, 0, 1],\n",
      " |         [0, 1, 0]])\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  label_binarize : function to perform the transform operation of\n",
      " |      LabelBinarizer with fixed classes.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LabelBinarizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, neg_label=0, pos_label=1, sparse_output=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, y)\n",
      " |      Fit label binarizer\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : numpy array of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Target values. The 2-d matrix should only contain 0 and 1,\n",
      " |          represents multilabel classification.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  inverse_transform(self, Y, threshold=None)\n",
      " |      Transform binary labels back to multi-class labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Y : numpy array or sparse matrix with shape [n_samples, n_classes]\n",
      " |          Target values. All sparse matrices are converted to CSR before\n",
      " |          inverse transformation.\n",
      " |      \n",
      " |      threshold : float or None\n",
      " |          Threshold used in the binary and multi-label cases.\n",
      " |      \n",
      " |          Use 0 when:\n",
      " |              - Y contains the output of decision_function (classifier)\n",
      " |          Use 0.5 when:\n",
      " |              - Y contains the output of predict_proba\n",
      " |      \n",
      " |          If None, the threshold is assumed to be half way between\n",
      " |          neg_label and pos_label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : numpy array or CSR matrix of shape [n_samples] Target values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the case when the binary labels are fractional\n",
      " |      (probabilistic), inverse_transform chooses the class with the\n",
      " |      greatest value. Typically, this allows to use the output of a\n",
      " |      linear model's decision_function method directly as the input\n",
      " |      of inverse_transform.\n",
      " |  \n",
      " |  transform(self, y)\n",
      " |      Transform multi-class labels to binary labels\n",
      " |      \n",
      " |      The output of transform is sometimes referred to by some authors as the\n",
      " |      1-of-K coding scheme.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : numpy array or sparse matrix of shape (n_samples,) or\n",
      " |          (n_samples, n_classes) Target values. The 2-d matrix should only\n",
      " |          contain 0 and 1, represents multilabel classification. Sparse\n",
      " |          matrix can be CSR, CSC, COO, DOK, or LIL.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Y : numpy array or CSR matrix of shape [n_samples, n_classes]\n",
      " |          Shape will be [n_samples, 1] for binary problems.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep: boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lb=preprocessing.LabelBinarizer()\n",
    "help(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyY=lb.fit_transform(labelList)\n",
    "dummyY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf=clf.fit(dummyX,dummyY)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([ 0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
